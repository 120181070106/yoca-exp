{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00abf240-a92f-42ec-856b-e0ed5d022832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model.\n",
      "initialize network with normal type\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:831: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n",
      "  if param.grad is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/l.pth model, and classes loaded.\n",
      "Configurations:\n",
      "----------------------------------------------------------------------\n",
      "|                     keys |                                   values|\n",
      "----------------------------------------------------------------------\n",
      "|               model_path |                               logs/l.pth|\n",
      "|             classes_path |               model_data/voc_classes.txt|\n",
      "|              input_shape |                               [640, 640]|\n",
      "|                      phi |                                        m|\n",
      "|               confidence |                                    0.001|\n",
      "|                  nms_iou |                                      0.5|\n",
      "|          letterbox_image |                                     True|\n",
      "|                     cuda |                                     True|\n",
      "----------------------------------------------------------------------\n",
      "Load model done.\n",
      "Get predict result.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get predict result done.\n",
      "Get ground truth result.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get ground truth result done.\n",
      "Get map.\n",
      "46.78% = 0 AP \t||\tscore_threhold=0.5 : F1=0.63 ; Recall=60.00% ; Precision=65.22%\n",
      "58.20% = 1 AP \t||\tscore_threhold=0.5 : F1=0.72 ; Recall=80.39% ; Precision=65.08%\n",
      "64.20% = 2 AP \t||\tscore_threhold=0.5 : F1=0.71 ; Recall=65.22% ; Precision=78.95%\n",
      "59.27% = 3 AP \t||\tscore_threhold=0.5 : F1=0.64 ; Recall=66.67% ; Precision=62.07%\n",
      "61.97% = 4 AP \t||\tscore_threhold=0.5 : F1=0.52 ; Recall=70.00% ; Precision=41.18%\n",
      "59.09% = 5 AP \t||\tscore_threhold=0.5 : F1=0.67 ; Recall=50.00% ; Precision=100.00%\n",
      "mAP = 58.25%\n",
      "Get map done.\n",
      "Get map.\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.562\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.529\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.717\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.717\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.717\n",
      "Get map done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.utils import get_classes\n",
    "from utils.utils_map import get_coco_map, get_map\n",
    "from yolo import YOLO\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    '''\n",
    "    Recall和Precision不像AP是一个面积的概念，因此在门限值（Confidence）不同时，网络的Recall和Precision值是不同的。\n",
    "    默认情况下，本代码计算的Recall和Precision代表的是当门限值（Confidence）为0.5时，所对应的Recall和Precision值。\n",
    "\n",
    "    受到mAP计算原理的限制，网络在计算mAP时需要获得近乎所有的预测框，这样才可以计算不同门限条件下的Recall和Precision值\n",
    "    因此，本代码获得的map_out/detection-results/里面的txt的框的数量一般会比直接predict多一些，目的是列出所有可能的预测框，\n",
    "    '''\n",
    "    #------------------------------------------------------------------------------------------------------------------#\n",
    "    #   map_mode用于指定该文件运行时计算的内容\n",
    "    #   map_mode为0代表整个map计算流程，包括获得预测结果、获得真实框、计算VOC_map。\n",
    "    #   map_mode为1代表仅仅获得预测结果。\n",
    "    #   map_mode为2代表仅仅获得真实框。\n",
    "    #   map_mode为3代表仅仅计算VOC_map。\n",
    "    #   map_mode为4代表利用COCO工具箱计算当前数据集的0.50:0.95map。需要获得预测结果、获得真实框后并安装pycocotools才行\n",
    "    #-------------------------------------------------------------------------------------------------------------------#\n",
    "    map_mode        = 0\n",
    "    #--------------------------------------------------------------------------------------#\n",
    "    #   此处的classes_path用于指定需要测量VOC_map的类别\n",
    "    #   一般情况下与训练和预测所用的classes_path一致即可\n",
    "    #--------------------------------------------------------------------------------------#\n",
    "    classes_path    = 'model_data/voc_classes.txt'\n",
    "    #--------------------------------------------------------------------------------------#\n",
    "    #   MINOVERLAP用于指定想要获得的mAP0.x，mAP0.x的意义是什么请同学们百度一下。\n",
    "    #   比如计算mAP0.75，可以设定MINOVERLAP = 0.75。\n",
    "    #\n",
    "    #   当某一预测框与真实框重合度大于MINOVERLAP时，该预测框被认为是正样本，否则为负样本。\n",
    "    #   因此MINOVERLAP的值越大，预测框要预测的越准确才能被认为是正样本，此时算出来的mAP值越低，\n",
    "    #--------------------------------------------------------------------------------------#\n",
    "    MINOVERLAP      = 0.5\n",
    "    #--------------------------------------------------------------------------------------#\n",
    "    #   受到mAP计算原理的限制，网络在计算mAP时需要获得近乎所有的预测框，这样才可以计算mAP\n",
    "    #   因此，confidence的值应当设置的尽量小进而获得全部可能的预测框。\n",
    "    #   \n",
    "    #   该值一般不调整。因为计算mAP需要获得近乎所有的预测框，此处的confidence不能随便更改。\n",
    "    #   想要获得不同门限值下的Recall和Precision值，请修改下方的score_threhold。\n",
    "    #--------------------------------------------------------------------------------------#\n",
    "    confidence      = 0.001\n",
    "    #--------------------------------------------------------------------------------------#\n",
    "    #   预测时使用到的非极大抑制值的大小，越大表示非极大抑制越不严格。\n",
    "    #   \n",
    "    #   该值一般不调整。\n",
    "    #--------------------------------------------------------------------------------------#\n",
    "    nms_iou         = 0.5\n",
    "    #---------------------------------------------------------------------------------------------------------------#\n",
    "    #   Recall和Precision不像AP是一个面积的概念，因此在门限值不同时，网络的Recall和Precision值是不同的。\n",
    "    #   \n",
    "    #   默认情况下，本代码计算的Recall和Precision代表的是当门限值为0.5（此处定义为score_threhold）时所对应的Recall和Precision值。\n",
    "    #   因为计算mAP需要获得近乎所有的预测框，上面定义的confidence不能随便更改。\n",
    "    #   这里专门定义一个score_threhold用于代表门限值，进而在计算mAP时找到门限值对应的Recall和Precision值。\n",
    "    #---------------------------------------------------------------------------------------------------------------#\n",
    "    score_threhold  = 0.5\n",
    "    #-------------------------------------------------------#\n",
    "    #   map_vis用于指定是否开启VOC_map计算的可视化\n",
    "    #-------------------------------------------------------#\n",
    "    map_vis         = False\n",
    "    #-------------------------------------------------------#\n",
    "    #   指向VOC数据集所在的文件夹\n",
    "    #   默认指向根目录下的VOC数据集\n",
    "    #-------------------------------------------------------#\n",
    "    VOCdevkit_path  = 'VOCdevkit'\n",
    "    #-------------------------------------------------------#\n",
    "    #   结果输出的文件夹，默认为map_out\n",
    "    #-------------------------------------------------------#\n",
    "    map_out_path    = 'map_out'\n",
    "\n",
    "    image_ids = open(os.path.join(VOCdevkit_path, \"VOC2007/ImageSets/Main/test.txt\")).read().strip().split()\n",
    "\n",
    "    if not os.path.exists(map_out_path):\n",
    "        os.makedirs(map_out_path)\n",
    "    if not os.path.exists(os.path.join(map_out_path, 'ground-truth')):\n",
    "        os.makedirs(os.path.join(map_out_path, 'ground-truth'))\n",
    "    if not os.path.exists(os.path.join(map_out_path, 'detection-results')):\n",
    "        os.makedirs(os.path.join(map_out_path, 'detection-results'))\n",
    "    if not os.path.exists(os.path.join(map_out_path, 'images-optional')):\n",
    "        os.makedirs(os.path.join(map_out_path, 'images-optional'))\n",
    "\n",
    "    class_names, _ = get_classes(classes_path)\n",
    "\n",
    "    if map_mode == 0 or map_mode == 1:\n",
    "        print(\"Load model.\")\n",
    "        yolo = YOLO(confidence = confidence, nms_iou = nms_iou)\n",
    "        print(\"Load model done.\")\n",
    "\n",
    "        print(\"Get predict result.\")\n",
    "        for image_id in tqdm(image_ids):\n",
    "            image_path  = os.path.join(VOCdevkit_path, \"VOC2007/JPEGImages/\"+image_id+\".jpg\")\n",
    "            image       = Image.open(image_path)\n",
    "            if map_vis:\n",
    "                image.save(os.path.join(map_out_path, \"images-optional/\" + image_id + \".jpg\"))\n",
    "            yolo.get_map_txt(image_id, image, class_names, map_out_path)\n",
    "        print(\"Get predict result done.\")\n",
    "        \n",
    "    if map_mode == 0 or map_mode == 2:\n",
    "        print(\"Get ground truth result.\")\n",
    "        for image_id in tqdm(image_ids):\n",
    "            with open(os.path.join(map_out_path, \"ground-truth/\"+image_id+\".txt\"), \"w\") as new_f:\n",
    "                root = ET.parse(os.path.join(VOCdevkit_path, \"VOC2007/Annotations/\"+image_id+\".xml\")).getroot()\n",
    "                for obj in root.findall('object'):\n",
    "                    difficult_flag = False\n",
    "                    if obj.find('difficult')!=None:\n",
    "                        difficult = obj.find('difficult').text\n",
    "                        if int(difficult)==1:\n",
    "                            difficult_flag = True\n",
    "                    obj_name = obj.find('name').text\n",
    "                    if obj_name not in class_names:\n",
    "                        continue\n",
    "                    bndbox  = obj.find('bndbox')\n",
    "                    left    = bndbox.find('xmin').text\n",
    "                    top     = bndbox.find('ymin').text\n",
    "                    right   = bndbox.find('xmax').text\n",
    "                    bottom  = bndbox.find('ymax').text\n",
    "\n",
    "                    if difficult_flag:\n",
    "                        new_f.write(\"%s %s %s %s %s difficult\\n\" % (obj_name, left, top, right, bottom))\n",
    "                    else:\n",
    "                        new_f.write(\"%s %s %s %s %s\\n\" % (obj_name, left, top, right, bottom))\n",
    "        print(\"Get ground truth result done.\")\n",
    "\n",
    "    if map_mode == 0 or map_mode == 3:\n",
    "        print(\"Get map.\")\n",
    "        get_map(MINOVERLAP, True, score_threhold = score_threhold, path = map_out_path)\n",
    "        print(\"Get map done.\")\n",
    "\n",
    "    # if map_mode == 4:\n",
    "        print(\"Get map.\")\n",
    "        get_coco_map(class_names = class_names, path = map_out_path)\n",
    "        print(\"Get map done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
